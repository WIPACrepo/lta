name: "CI/CD"

on:
  # only on branch pushes
  push:
    branches:
      - '**'
    tags-ignore:
      - '**'


concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  # don't cancel on main/master/default
  cancel-in-progress: ${{ format('refs/heads/{0}', github.event.repository.default_branch) != github.ref }}


env:
  CI_DOCKER_IMAGE_W_TAG: lta/test:local


jobs:

  #############################################################################
  # TOOLS FOR SETTING UP MATRIX-BASED JOBS
  #############################################################################

  mongo-versions:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.versions.outputs.matrix }}
    steps:
      - uses: actions/checkout@v6
        with:
          ref: ${{ github.sha }}  # lock to triggered commit (github.ref is dynamic)
      - id: versions
        uses: WIPACrepo/wipac-dev-mongo-versions-action@v2
        with:
          mongo_min: "5.0"

  py-versions:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.versions.outputs.matrix }}
    steps:
      - uses: actions/checkout@v6
        with:
          ref: ${{ github.sha }}  # lock to triggered commit (github.ref is dynamic)
      - id: versions
        uses: WIPACrepo/wipac-dev-py-versions-action@v2.8


  #############################################################################
  # LINTERS
  #############################################################################

  flake8:
    needs: [ py-versions ]
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        py3: ${{ fromJSON(needs.py-versions.outputs.matrix) }}
    steps:
      - uses: actions/checkout@v6
        with:
          ref: ${{ github.sha }}  # lock to triggered commit (github.ref is dynamic)
      - uses: actions/setup-python@v6
        with:
          python-version: ${{ matrix.py3 }}
      - uses: WIPACrepo/wipac-dev-flake8-action@v1.3
        with:
          max-complexity: 10  # ideal is ~10-15

  mypy:
    needs: [ py-versions ]
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        py3: ${{ fromJSON(needs.py-versions.outputs.matrix) }}
    steps:
      - uses: actions/checkout@v6
        with:
          ref: ${{ github.sha }}  # lock to triggered commit (github.ref is dynamic)
          fetch-depth: 0  # setuptools-scm needs to access git tags
      - uses: actions/setup-python@v6
        with:
          python-version: ${{ matrix.py3 }}
      - uses: WIPACrepo/wipac-dev-mypy-action@v2.0


  #############################################################################
  # PACKAGING
  #############################################################################

  py-setup:
    if: ${{ github.actor != 'dependabot[bot]' }} # dependabot cannot access PAT
    needs: [
      # linters so we don't waste compute on faulty code...
      flake8,
      mypy,
    ]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6
        with:
          token: ${{ secrets.PERSONAL_ACCESS_TOKEN }}
          ref: ${{ github.ref }}  # dont lock to sha (action needs to push)
      - uses: WIPACrepo/wipac-dev-py-setup-action@v5.9
        with:
          mode: PACKAGING
          python_min: "3.11"  # asyncio.TaskGroup
          python_max: "3.13"
          author: WIPAC Developers
          author_email: developers@icecube.wisc.edu
          keywords_comma: "archive, data, IceCube, WIPAC"
          auto_mypy_option: True

  py-dependencies:
    needs: [
      # linters so we don't waste compute on faulty code...
      flake8,
      # mypy,  # sometimes its useful to see our deps if mypy fails
    ]
    runs-on: ubuntu-latest
    steps:
      # optimization: ask the action if it would proceed before building our expensive images
      - uses: WIPACrepo/wipac-dev-py-dependencies-action@v3.4
        id: pydep-precheck
        with:
          only_precheck: true

      # pre-check passed, so proceed...
      - if: ${{ steps.pydep-precheck.outputs.do_generation == 'true' }}
        uses: actions/checkout@v6
        with:
          ref: ${{ github.sha }}  # lock to triggered commit (github.ref is dynamic)
          fetch-depth: 0  # setuptools-scm needs to access git tags
      - if: ${{ steps.pydep-precheck.outputs.do_generation == 'true' }}
        uses: docker/setup-buildx-action@v3
      - if: ${{ steps.pydep-precheck.outputs.do_generation == 'true' }}
        uses: docker/build-push-action@v6
        with:
          context: .
          file: Dockerfile
          tags: lta:py-dep-this
          load: true
      - if: ${{ steps.pydep-precheck.outputs.do_generation == 'true' }}
        uses: WIPACrepo/wipac-dev-py-dependencies-action@v3.4


  ############################################################################
  # TESTS
  #############################################################################

  unit-tests:
    needs: [ py-versions ]
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        py3: ${{ fromJSON(needs.py-versions.outputs.matrix) }}
    steps:
      - uses: actions/checkout@v6
        with:
          ref: ${{ github.sha }}  # lock to triggered commit (github.ref is dynamic)
          fetch-depth: 0  # setuptools-scm needs to access git tags
      - uses: actions/setup-python@v6
        with:
          python-version: ${{ matrix.py3 }}
      - name: Pytest
        env:
          CI_TEST_ENV: true
        run: |
          set -euo pipefail; echo "now: $(date -u +"%Y-%m-%dT%H:%M:%S.%3N")"
          source ./tools/setupenv.sh
          pytest -vvvvv tests/unit/

  test-build-docker:
    needs: [
      # linters so we don't waste compute on faulty code...
      flake8,
      mypy,
      unit-tests,
    ]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6
        with:
          ref: ${{ github.sha }}  # lock to triggered commit (github.ref is dynamic)
          fetch-depth: 0  # setuptools-scm needs to access git tags
      - uses: docker/setup-buildx-action@v3
      - uses: docker/build-push-action@v6
        with:
          context: .
          cache-from: type=gha
          cache-to: type=gha,mode=min
          file: Dockerfile
          tags: ${{ env.CI_DOCKER_IMAGE_W_TAG }}

  integration-test-rest-server:
    needs: [
      mongo-versions,
      py-versions,
      # linters so we don't waste compute on faulty code...
      flake8,
      mypy,
      unit-tests,
    ]
    runs-on: ubuntu-latest
    strategy:
      fail-fast: true
      matrix:
        py3: ${{ fromJSON(needs.py-versions.outputs.matrix) }}
        mongodb-version: ${{ fromJSON(needs.mongo-versions.outputs.matrix) }}
    steps:
      - uses: actions/checkout@v6
        with:
          ref: ${{ github.sha }}  # lock to triggered commit (github.ref is dynamic)
          fetch-depth: 0  # setuptools-scm needs to access git tags
      - uses: actions/setup-python@v6
        with:
          python-version: ${{ matrix.py3 }}
      # MONGO
      - name: Start MongoDB v${{ matrix.mongodb-version }}
        uses: supercharge/mongodb-github-action@1.12.1
        with:
          mongodb-version: ${{ matrix.mongodb-version }}
      # DOCKER IMAGE
      - uses: docker/setup-buildx-action@v3
      - uses: docker/build-push-action@v6
        with:
          context: .
          cache-from: type=gha
          cache-to: type=gha,mode=min
          file: Dockerfile
          tags: ${{ env.CI_DOCKER_IMAGE_W_TAG }}
          build-args: |
            PYTHON=${{ matrix.py3 }}
          load: true
      # TEST SCRIPT
      - name: test
        run: |
          set -euo pipefail; echo "now: $(date -u +"%Y-%m-%dT%H:%M:%S.%3N")"
          
          # grab the dependencies needed for pytest and friends
          pip install tomli
          dev_reqs=$( python -c "import tomli; d=tomli.load(open('pyproject.toml','rb')); print(' '.join(d['project']['optional-dependencies']['dev']))" )
          
          # run pytest in container
          set -x
          mkdir -p ./metrics
          chmod 777 ./metrics
          docker run --rm \
              --network='host' \
              --mount type=bind,source="$( realpath ./tests )",target="/app/tests",readonly \
              --mount type=bind,source="$( realpath ./metrics )",target="/app/metrics" \
              --env CI \
              --env DUMP_PROMETHEUS_METRICS_FILE="/app/metrics/metrics.prom" \
              ${{ env.CI_DOCKER_IMAGE_W_TAG }} \
              /bin/bash -c "\
                pip install $dev_reqs && \
                resources/enable_profiling.py && \
                pytest -vvvvv tests/integration/test_rest_server.py --exitfirst && \
                resources/profile_queries.py \
              "

      - name: dump prometheus metrics
        if: always()
        run: |
          set -euo pipefail; echo "now: $(date -u +"%Y-%m-%dT%H:%M:%S.%3N")"

          if [[ ! -f ./metrics/metrics.prom ]]; then
              echo "<no metrics file>"
              exit 0
          fi

          echo "=== metrics file (head) ==="
          head -n 40 ./metrics/metrics.prom

          # prom2json (Go tool)
          go install github.com/prometheus/prom2json/cmd/prom2json@latest
          _gobin="$(go env GOPATH)/bin"
          export PATH="${_gobin}:${PATH}"
          echo "${_gobin}" >> "$GITHUB_PATH"
          command -v prom2json

          # termgraph (Python tool)
          pip install --disable-pip-version-check -q termgraph

          # Convert once, reuse
          prom2json ./metrics/metrics.prom > /tmp/metrics.json
          
          # Enumerate every histogram series labelset (method/route/status, plus anything else present)
          jq -c '
            .[]
            | select(.name=="http_request_duration_seconds")
            | .metrics[]
            | .labels
          ' /tmp/metrics.json | sort -u > /tmp/histo-labels.jsonl
          
          echo "Found $(wc -l < /tmp/histo-labels.jsonl) histogram series"
          
          # Helper: render one series (delta buckets with range labels)
          render_one() {
              _labels_json="$1"
          
              # Header: labels + count/sum/avg if available
              jq -r --argjson L "$_labels_json" '
                .[]
                | select(.name=="http_request_duration_seconds")
                | .metrics[]
                | select(.labels == $L)
                | . as $m
                | "=== http_request_duration_seconds "
                  + ($m.labels | to_entries | sort_by(.key) | map("\(.key)=\(.value)") | join(" "))
                  + (if ($m.count? != null) then
                       " | count=\($m.count) sum=\($m.sum) avg=\((($m.sum|tonumber)/($m.count|tonumber)))"
                     else
                       ""
                     end)
              ' /tmp/metrics.json
          
              # Build delta buckets for this series
              jq -r --argjson L "$_labels_json" '
                def le_num:
                  if .key=="+Inf" then 1e100 else (.key|tonumber) end;
          
                def fmt_range(prev; le):
                  if le=="+Inf" then ">(" + prev + ")"
                  else "(" + prev + "," + le + "]"
                  end;
          
                def clamp0(x):
                  if x < 0 then 0 else x end;
          
                .[]
                | select(.name=="http_request_duration_seconds")
                | .metrics[]
                | select(.labels == $L)
                | (.buckets | to_entries | sort_by(le_num)) as $b
                | reduce range(0; ($b|length)) as $i (
                    {prev_edge: "0", prev_val: 0, out: []};
                    ($b[$i].key) as $le
                    | (($b[$i].value|tonumber)) as $cur
                    | (($cur - .prev_val) | clamp0(.)) as $delta
                    | .out += [ {label: fmt_range(.prev_edge; $le), v: $delta} ]
                    | .prev_edge = $le
                    | .prev_val = $cur
                  )
                | .out[]
                | select(.v > 0.0000001)
                | "\(.label) \(.v)"
              ' /tmp/metrics.json > /tmp/hist.dat
          
              if [[ ! -s /tmp/hist.dat ]]; then
                  echo "<no observations>"
                  echo
                  return 0
              fi
          
              termgraph /tmp/hist.dat --width 60
              echo
          }
          
          # Render them all
          while IFS= read -r _labels; do
              render_one "$_labels"
          done < /tmp/histo-labels.jsonl


  #############################################################################
  # GIT TAG & GITHUB RELEASE
  #############################################################################

  tag-and-release:
    # only run on main/default branch
    if: format('refs/heads/{0}', github.event.repository.default_branch) == github.ref
    needs: [
      mongo-versions,
      py-versions,
      flake8,
      mypy,
      py-setup,
      py-dependencies,
      unit-tests,
      test-build-docker,
      integration-test-rest-server,
    ]
    uses: WIPACrepo/wipac-dev-workflows/.github/workflows/tag-and-release.yml@v1.20
    permissions: # for GITHUB_TOKEN
      contents: write
    with:
      project-type: python
      python-version: "${{ fromJSON(needs.py-versions.outputs.matrix)[0] }}"
      release-artifacts: |
        py-dependencies-logs
    secrets:
      TOKEN: ${{ secrets.PERSONAL_ACCESS_TOKEN }}  # trigger tag-event gha workflows
